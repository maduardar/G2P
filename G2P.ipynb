{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Masking, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Bidirectional, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{input_data}$ is a 2-dementional array. $\\textit{input_data[0]}$ includes all graphemes and $\\textit{input_data[1]}$ includes all phonemes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = open('train.txt', 'r')\n",
    "input_data = [[], []]\n",
    "g2p_dict, p2g_dict = {}, {}\n",
    "for lines in text:\n",
    "    line = lines.split()\n",
    "    grapheme = line[0]\n",
    "    for phoneme in line[1:]:\n",
    "        g2p_dict.update({grapheme : phoneme})\n",
    "        p2g_dict.update({phoneme : grapheme})\n",
    "        input_data[0].append(grapheme)\n",
    "        input_data[1].append(phoneme)\n",
    "#input_data = np.array(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 example data:\n",
      "LEMIEUX \tMINDING \tSTRIPED \tKEN \tCONFERENCE\n",
      "L_AH_M_Y_UW \tM_AY_N_D_IH_NG \tS_T_R_AY_P_T \tK_EH_N \tK_AA_N_F_ER_AH_N_S\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "print('First %d example data:' %n)\n",
    "print(' \\t'.join(input_data[0][:n]))\n",
    "print(' \\t'.join(input_data[1][:n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 32\n"
     ]
    }
   ],
   "source": [
    "def makeVocabularySet(data, sep = False):\n",
    "    vocab = {}\n",
    "    sequences = [] \n",
    "    max_seq_len = 0\n",
    "    i = 0\n",
    "    for rows in data:\n",
    "        if sep:\n",
    "            rows = rows.split('_')\n",
    "        if len(rows) > max_seq_len:\n",
    "            max_seq_len = len(rows)\n",
    "        for c in rows:\n",
    "            if c in vocab.keys():\n",
    "                continue\n",
    "            vocab.update({c : i})\n",
    "            i += 1\n",
    "    rev_vocab = dict((v, k) for (k, v) in vocab.items())\n",
    "    return max_seq_len, vocab, rev_vocab\n",
    "graph_max_seq_len, grapheme_encoder, grapheme_decoder = makeVocabularySet(input_data[0])\n",
    "phone_max_seq_len, phoneme_encoder, phoneme_decoder = makeVocabularySet(input_data[1], True)\n",
    "print(graph_max_seq_len, phone_max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add $\\textit{go}$ and $\\textit{end}$ tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ПРОВЕРКА 41 41\n"
     ]
    }
   ],
   "source": [
    "# Не заупскай этот код дважды\n",
    "def add_token(vocab, rev_vocab, token):\n",
    "    n = len(vocab)\n",
    "    vocab.update({token : n})\n",
    "    rev_vocab.update({n : token})\n",
    "add_token(phoneme_encoder, phoneme_decoder, '<go>')\n",
    "add_token(phoneme_encoder, phoneme_decoder, '<end>')\n",
    "add_token(grapheme_encoder, grapheme_decoder, '<end>')\n",
    "print('ПРОВЕРКА', len(phoneme_decoder), len(phoneme_encoder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<end>\n",
      "<end>\n"
     ]
    }
   ],
   "source": [
    "print(phoneme_decoder[40])\n",
    "print(grapheme_decoder[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_grapheme = len(grapheme_encoder)\n",
    "num_phoneme = len(phoneme_encoder)\n",
    "graphemes = input_data[0]\n",
    "phonemes = input_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(graphemes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(graphemes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded graphemes:\n",
      "LEMIEUX \t\tMINDING \t\tSTRIPED \t\tKEN\n",
      "[0, 1, 2, 3, 1, 4, 5, 28][2, 3, 6, 7, 3, 6, 8, 28][9, 10, 11, 3, 12, 1, 7, 28][13, 1, 6, 28]\n",
      "Encoded phonemes:\n",
      "L_AH_M_Y_UW \t\tM_AY_N_D_IH_NG \t\tS_T_R_AY_P_T \t\tK_EH_N\n",
      "[39, 0, 1, 2, 3, 4, 40][39, 2, 5, 6, 7, 8, 9, 40][39, 10, 11, 12, 5, 13, 11, 40][39, 14, 15, 6, 40]\n"
     ]
    }
   ],
   "source": [
    "def encode_sequence(data, vocab, split = False):\n",
    "    encoded = []\n",
    "    for rows in data:\n",
    "        if split:\n",
    "            rows = '<go>_' + rows   #  add go-token (for phonemes only)\n",
    "            rows = rows.split('_')\n",
    "        tmp = list(map(lambda x: vocab[x], rows))  \n",
    "        tmp.append(vocab['<end>'])   # add end-token\n",
    "        encoded.append(tmp)\n",
    "    return np.array(encoded)\n",
    "encoded_graphemes = encode_sequence(graphemes, grapheme_encoder)\n",
    "graph_max_seq_len += 1\n",
    "encoded_phonemes = encode_sequence(phonemes, phoneme_encoder, True)\n",
    "phone_max_seq_len += 2\n",
    "print('Encoded graphemes:')\n",
    "print(' \\t\\t'.join(graphemes[:4]))\n",
    "print(''.join(map(str, encoded_graphemes[:4])))\n",
    "\n",
    "print('Encoded phonemes:')\n",
    "print(' \\t\\t'.join(phonemes[:4]))\n",
    "print(''.join(map(str, encoded_phonemes[:4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n"
     ]
    }
   ],
   "source": [
    "print(max(map(len, encoded_graphemes)), graph_max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(encoded_graphemes[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded grapheme:\n",
      "LEMIEUX\n",
      "[0, 1, 2, 3, 1, 4, 5, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28]\n",
      "Padded phoneme:\n",
      "L_AH_M_Y_UW\n",
      "[39, 0, 1, 2, 3, 4, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40]\n"
     ]
    }
   ],
   "source": [
    "def padding(data, vocab):\n",
    "    padded = []\n",
    "    max_len = max(graph_max_seq_len, phone_max_seq_len)\n",
    "    for row in data:\n",
    "        add = [vocab['<end>'] for i in range(max_len - len(row))]\n",
    "        padded.append(row + add)\n",
    "    return padded\n",
    "padded_graphemes = padding(encoded_graphemes, grapheme_encoder)\n",
    "padded_phonemes = padding(encoded_phonemes, phoneme_encoder)\n",
    "print('Padded grapheme:')\n",
    "print(' \\t\\t'.join(graphemes[:1]))\n",
    "print(''.join(map(str, padded_graphemes[:1])))\n",
    "\n",
    "print('Padded phoneme:')\n",
    "print(' \\t\\t'.join(phonemes[:1]))\n",
    "print(''.join(map(str, padded_phonemes[:1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(data, vocab):\n",
    "    shp = [len(data), len(data[0]), len(vocab)]\n",
    "    train_data = np.zeros((shp[0], shp[1], shp[2]), dtype=np.int)\n",
    "    for i in range(shp[0]):\n",
    "        j = 0\n",
    "        for k in data[i]:\n",
    "            train_data[i][j][k] = 1\n",
    "            j += 1\n",
    "    i += 1\n",
    "    return train_data\n",
    "X_train = vectorization(padded_graphemes, grapheme_encoder)\n",
    "y_train = vectorization(padded_phonemes, phoneme_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (89056, 35, 29)\n",
      "y_train shape: (89056, 35, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 1, 4, 5, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "print(padded_graphemes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (by Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, activation=\"tanh\", return_sequences=True, recurrent_activation=\"hard_sigmoid\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, activation=\"tanh\", return_sequences=True, go_backwards=True, recurrent_activation=\"hard_sigmoid\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(64, return_sequences=True, recurrent_activation=\"hard_sigmoid\")`\n",
      "  if sys.path[0] == '':\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(64, return_sequences=True, go_backwards=True, recurrent_activation=\"hard_sigmoid\")`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "outs = y_train.shape[2]\n",
    "outs1 = y_train.shape[1]\n",
    "max_len, feats = X_train.shape[1], X_train.shape[2]\n",
    "hidden_l = 64\n",
    "batch_size = 100\n",
    "epochs = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(max_len, feats)))\n",
    "model.add(LSTM(hidden_l, return_sequences=True, activation='tanh', inner_activation='hard_sigmoid'))\n",
    "model.add(LSTM(hidden_l, return_sequences=True, activation='tanh', inner_activation='hard_sigmoid', go_backwards=True))\n",
    "model.add(GRU(hidden_l, return_sequences=True, inner_activation='hard_sigmoid'))\n",
    "model.add(GRU(hidden_l, return_sequences=True, inner_activation='hard_sigmoid', go_backwards=True))\n",
    "model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(outs, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "46200/89056 [==============>...............] - ETA: 4:19 - loss: 0.6623"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 35, 29)\n"
     ]
    }
   ],
   "source": [
    "def word_to_vector(word):\n",
    "    encoded = encode_sequence(word, grapheme_encoder)\n",
    "    padded = padding(encoded, grapheme_encoder)\n",
    "    return vectorization(padded, grapheme_encoder)\n",
    "words = ['HELLO', 'CONFERENCE', 'ELEVEN']\n",
    "x = word_to_vector(words)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 35, 29)\n",
      "3/3 [==============================] - 3s 835ms/step\n"
     ]
    }
   ],
   "source": [
    "# x = X_train[0]\n",
    "# n = X_train.shape[1]\n",
    "# x = x.reshape((1, n, -1))\n",
    "print(x.shape)\n",
    "pred = model.predict(x, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<go>_IH_L_IH_V_N_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>_<end>\n"
     ]
    }
   ],
   "source": [
    "decode = lambda x : phoneme_decoder[np.argmax(x)]\n",
    "print('_'.join(map(decode, pred[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 41)\n"
     ]
    }
   ],
   "source": [
    "print(pred[0].shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to use seq2seq-model\n",
    "\n",
    "attempt failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(gra_vocab_size, pho_vocab_size, embedding_dim=10, num_hidden_units=50, learning_rate=0.001,\n",
    "                use_dropout=False, keep_prob=0.8):\n",
    "    # Placeholders for data input\n",
    "    with tf.variable_scope(\"data_input_placeholders\") as data_input_placeholders_scope:\n",
    "        # input in batch-major format: batch_size x g_seq_len\n",
    "        gra_inputs = tf.placeholder(tf.int32, (None, None), name='grapheme_inputs')\n",
    "        # variable length grapheme sequences with shape batch_size\n",
    "        gra_input_lens = tf.placeholder(tf.int32, (None), name='grapheme_seq_lengths')\n",
    "\n",
    "        # output of decoder will be the phonemes also with shape batch_size x p_seq_len\n",
    "        dec_pho_inputs = tf.placeholder(tf.int32, (None, None), name='phoneme_decoder_inputs')\n",
    "        # variable length phoneme sequences with shape batch_size\n",
    "        dec_pho_inputs_lens = tf.placeholder(tf.int32, (None), name='phoneme_decoder_input_lengths')\n",
    "\n",
    "        # labels (teacher forcing) with shape batch_size x p_seq_len\n",
    "        pho_labels = tf.placeholder(tf.int32, (None, None), name='phoneme_labels')\n",
    "\n",
    "    # Embedding layers\n",
    "    with tf.variable_scope(\"embeddings\") as embedding_scope:\n",
    "        gra_embeddings = tf.Variable(tf.random_uniform([gra_vocab_size, embedding_dim], -1.0, 1.0), dtype=tf.float32,\n",
    "                                     name='grapheme_embedding')\n",
    "        # gra_inputs_embedded: [batch_size, time_step, embedding_dim] -> batch major format\n",
    "        gra_inputs_embedded = tf.nn.embedding_lookup(gra_embeddings, gra_inputs)\n",
    "\n",
    "        pho_embeddings = tf.Variable(tf.random_uniform([pho_vocab_size, embedding_dim], -1.0, 1.0), dtype=tf.float32,\n",
    "                                     name='phoneme_embedding')\n",
    "        # pho_output_embedded: [batch_size, time_step, embedding_dim] -> batch major format\n",
    "        dec_pho_inputs_embedded = tf.nn.embedding_lookup(pho_embeddings, dec_pho_inputs)\n",
    "\n",
    "    # create encoder and decoder LSTMs\n",
    "    with tf.variable_scope(\"encoding\") as encoding_scope:\n",
    "        lstm_enc = tfc.rnn.BasicLSTMCell(num_hidden_units)\n",
    "\n",
    "        # Dropout (= 1 - keep_prob)\n",
    "        if use_dropout:\n",
    "            dropout = 1 - keep_prob\n",
    "            if dropout < 0.0:\n",
    "                dropout = .2\n",
    "                keep_prob = 1.0 - dropout\n",
    "            lstm_enc = tf.contrib.rnn.DropoutWrapper(cell=lstm_enc, input_keep_prob=keep_prob)\n",
    "\n",
    "        _, last_state = tf.nn.dynamic_rnn(lstm_enc, inputs=gra_inputs_embedded, sequence_length=gra_input_lens,\n",
    "                                          dtype=tf.float32)\n",
    "\n",
    "    with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "        # encoder initial state is last_state of encoder\n",
    "        lstm_dec = tfc.rnn.BasicLSTMCell(num_hidden_units)\n",
    "\n",
    "        # Dropout (= 1 - keep_prob)\n",
    "        if use_dropout:\n",
    "            dropout = 1 - keep_prob\n",
    "            if dropout < 0.0:\n",
    "                dropout = .2\n",
    "                keep_prob = 1.0 - dropout\n",
    "            lstm_dec = tf.contrib.rnn.DropoutWrapper(cell=lstm_enc, input_keep_prob=keep_prob)\n",
    "\n",
    "        dec_outputs, _ = tf.nn.dynamic_rnn(lstm_dec, inputs=dec_pho_inputs_embedded,\n",
    "                                           sequence_length=dec_pho_inputs_lens,\n",
    "                                           initial_state=last_state, dtype=tf.float32)\n",
    "\n",
    "    # output projection\n",
    "    with tf.name_scope(\"output_projection\"):\n",
    "        logits = tfc.layers.fully_connected(dec_outputs, num_outputs=pho_vocab_size, activation_fn=tf.nn.softmax)\n",
    "    \"\"\"\n",
    "        weights = tf.Variable(tf.random_uniform([num_hidden_units, pho_vocab_size], -0.01, 0.01, dtype=tf.float32))\n",
    "        b = tf.Variable(tf.random_uniform([pho_vocab_size], -0.01, 0.01, dtype=tf.float32))\n",
    "        predictions = tf.add(tf.matmul(dec_outputs, weights), b)\n",
    "    \"\"\"\n",
    "\n",
    "    logits_argmax = tf.argmax(logits, axis=-1)\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        # TODO\n",
    "\n",
    "        # get dynamic batch_size\n",
    "        batch_size = tf.shape(gra_inputs)[0]\n",
    "        # get dynamic output seq len\n",
    "        pho_output_len = tf.shape(dec_pho_inputs)[0]\n",
    "\n",
    "        loss = tfc.seq2seq.sequence_loss(logits, pho_labels, tf.ones([batch_size, pho_output_len]),\n",
    "                                         average_across_batch=True, average_across_timesteps=True)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    return gra_inputs, gra_input_lens, dec_pho_inputs, dec_pho_inputs_lens, pho_labels, optimizer, loss, logits, logits_argmax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grapheme_sequences_train, grapheme_sequences_test, phoneme_sequences_train, phoneme_sequences_test = train_test_split(\n",
    "        encoded_graphemes, encoded_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_hidden_units = 128\n",
    "embedding_dim = 100\n",
    "epochs = 2\n",
    "batch_size = 1\n",
    "use_dropout = True\n",
    "keep_prob = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tfc\n",
    "gra_inputs, gra_input_lens, dec_pho_inputs, dec_pho_input_lens, pho_labels, optimizer, loss, logits, logits_argmax = build_graph(\n",
    "        num_grapheme,\n",
    "        num_phoneme,\n",
    "        embedding_dim=embedding_dim,\n",
    "        num_hidden_units=num_hidden_units,\n",
    "        learning_rate=learning_rate,\n",
    "        use_dropout=use_dropout,\n",
    "        keep_prob=keep_prob,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "init_op = tf.global_variables_initializer()\n",
    "summary_merge_op = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0: \n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape [-1,-1] has negative dimensions\n\t [[Node: data_input_placeholders/grapheme_inputs = Placeholder[dtype=DT_INT32, shape=[?,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'data_input_placeholders/grapheme_inputs', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-bfd994f103df>\", line 10, in <module>\n    keep_prob=keep_prob,\n  File \"<ipython-input-9-87b3d2b8e28a>\", line 6, in build_graph\n    gra_inputs = tf.placeholder(tf.int32, (None, None), name='grapheme_inputs')\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,-1] has negative dimensions\n\t [[Node: data_input_placeholders/grapheme_inputs = Placeholder[dtype=DT_INT32, shape=[?,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,-1] has negative dimensions\n\t [[Node: data_input_placeholders/grapheme_inputs = Placeholder[dtype=DT_INT32, shape=[?,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-61e343ef59a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                       pho_labels: label_batch}\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logits_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits_argmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,-1] has negative dimensions\n\t [[Node: data_input_placeholders/grapheme_inputs = Placeholder[dtype=DT_INT32, shape=[?,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'data_input_placeholders/grapheme_inputs', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-bfd994f103df>\", line 10, in <module>\n    keep_prob=keep_prob,\n  File \"<ipython-input-9-87b3d2b8e28a>\", line 6, in build_graph\n    gra_inputs = tf.placeholder(tf.int32, (None, None), name='grapheme_inputs')\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1530, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1954, in _placeholder\n    name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,-1] has negative dimensions\n\t [[Node: data_input_placeholders/grapheme_inputs = Placeholder[dtype=DT_INT32, shape=[?,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "def generate_batch_data(gra_seqs, pho_seqs, batch_size=1):\n",
    "    start = 0\n",
    "    shuffle = np.random.permutation(len(pho_seqs))\n",
    "    gra_seqs = gra_seqs[shuffle]\n",
    "    pho_seqs = pho_seqs[shuffle]\n",
    "    while start + batch_size <= len(gra_seqs):\n",
    "        enc_inputs = []\n",
    "        enc_input_lens = []\n",
    "        dec_inputs = []\n",
    "        dec_input_lens = []\n",
    "        labels = []\n",
    "        for g in gra_seqs[start:start + batch_size]:\n",
    "            enc_inputs.append(g)\n",
    "            enc_input_lens.append(len(g))\n",
    "        for p in pho_seqs[start:start + batch_size]:\n",
    "            # dec_inputs doesn't contain last char -> end_token\n",
    "            dec_inputs.append(p[:-1])\n",
    "            # since pho_seqs have an appended <GO> token, the length has to be decreased by 1\n",
    "            dec_input_lens.append(len(p) - 1)\n",
    "            # labels doesn't contain first char -> go_token\n",
    "            labels.append(p[1:])\n",
    "\n",
    "        enc_inputs = np.array(enc_inputs)\n",
    "        enc_input_lens = np.array(enc_input_lens)\n",
    "        dec_inputs = np.array(dec_inputs)\n",
    "        dec_input_lens = np.array(dec_input_lens)\n",
    "\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        yield enc_inputs, enc_input_lens, dec_inputs, dec_input_lens, labels\n",
    "        start += batch_size\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    writer = tf.summary.FileWriter('Phoneme', graph=sess.graph)\n",
    "    for epoch_i in range(epochs):\n",
    "        accuracies = []\n",
    "        batch_losses = []\n",
    "        print(\"Epoch {:3}: \".format(epoch_i))\n",
    "        start = time.time()\n",
    "        for batch_i, (\n",
    "                input_batch, input_lens_batch, dec_input_batch, dec_input_lens_batch, label_batch) in enumerate(\n",
    "            generate_batch_data(grapheme_sequences_train, phoneme_sequences_train, batch_size)):\n",
    "            # build feed dict\n",
    "            f_dict = {gra_inputs: input_batch,\n",
    "                      gra_input_lens: input_lens_batch,\n",
    "                      dec_pho_inputs: dec_input_batch,\n",
    "                      dec_pho_input_lens: dec_input_lens_batch,\n",
    "                      pho_labels: label_batch}\n",
    "\n",
    "            _, batch_loss, batch_logits, batch_logits_argmax = sess.run([optimizer, loss, logits, logits_argmax])\n",
    "            batch_accuracy = np.mean(batch_logits.argmax(axis=-1) == label_batch)\n",
    "            accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LSTM-model (by Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

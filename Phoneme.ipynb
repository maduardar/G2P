{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Masking, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = open('train.txt', 'r')\n",
    "word_dict = {}\n",
    "X_data, Y_data = [], []\n",
    "for lines in text:\n",
    "    line = lines.split()\n",
    "    for words in line[1:]:\n",
    "        word_dict.update({line[0] : words})\n",
    "        X_data.append(line[0])\n",
    "        Y_data.append(words)\n",
    "X_data, Y_data = np.array(X_data), np.array(Y_data)\n",
    "dictionary = word_dict\n",
    "reverse_dictionary = dict([(v, k) for k, v in dictionary.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LEMIEUX' 'MINDING' 'STRIPED' 'KEN' 'CONFERENCE' 'CONFERENCE' 'IMMOLATE'\n",
      " 'TRANSGRESS' 'RABBLE' 'AIRSHARE']\n"
     ]
    }
   ],
   "source": [
    "print(X_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L_AH_M_Y_UW' 'M_AY_N_D_IH_NG' 'S_T_R_AY_P_T' 'K_EH_N'\n",
      " 'K_AA_N_F_ER_AH_N_S' 'K_AA_N_F_R_AH_N_S' 'IH_M_AH_L_EY_T'\n",
      " 'T_R_AE_N_Z_G_R_EH_S' 'R_AE_B_AH_L' 'EH_R_SH_EH_R']\n"
     ]
    }
   ],
   "source": [
    "print(Y_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Баловство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G \t 6149 \t JH\n",
      "D \t 11830 \t IY\n",
      "W \t 2861 \t AH\n",
      "A \t 0 \t AE\n",
      "Q \t 0 \t K\n",
      "T \t 17953 \t T\n",
      "E \t 0 \t ER\n",
      "F \t 5558 \t L\n",
      "Z \t 2059 \t Z\n",
      "J \t 0 \t JH\n",
      "K \t 5390 \t S\n",
      "Y \t 572 \t M\n",
      "L \t 19248 \t L\n",
      "H \t 0 \t M\n",
      "S \t 16704 \t S\n",
      "M \t 12604 \t AH\n",
      "X \t 0 \t K\n",
      "C \t 0 \t AA\n",
      "V \t 4887 \t L\n",
      "O \t 0 \t AA\n",
      "I \t 0 \t ER\n",
      "N \t 21153 \t Z\n",
      "P \t 9562 \t P\n",
      "R \t 20421 \t D\n",
      "B \t 9753 \t B\n",
      "U \t 0 \t IY\n"
     ]
    }
   ],
   "source": [
    "simb2phonDict = {}\n",
    "gr2coinc = {}\n",
    "from string import ascii_uppercase\n",
    "for let in ascii_uppercase:\n",
    "    gr2coinc.update({let: 0})\n",
    "phoneme_set = set()\n",
    "phonemes = reverse_dictionary.keys()\n",
    "ok = 0\n",
    "sz3 = 0\n",
    "for phoneme in phonemes:\n",
    "    grapheme = list(reverse_dictionary[phoneme])\n",
    "    phoneme = phoneme.split('_')\n",
    "    if len(phoneme) > sz3:\n",
    "        sz3 = len(phoneme)\n",
    "    for p in phoneme:\n",
    "        phoneme_set.add(p)\n",
    "    sz = min(len(grapheme), len(phoneme))\n",
    "    for i in range(sz):\n",
    "        simb2phonDict.update({grapheme[i]: phoneme[i]})\n",
    "        if grapheme[i] == phoneme[i]:\n",
    "            gr2coinc[grapheme[i]] += 1\n",
    "for g in gr2coinc.keys():\n",
    "    print(g, \"\\t\", gr2coinc[g], \"\\t\", simb2phonDict[g])\n",
    "# for g in simb2phonDict.keys():\n",
    "#     print(g, \"\\t\", simb2phonDict[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_vocab = {}\n",
    "for let in ascii_uppercase:\n",
    "    X_vocab.update({let: 0})\n",
    "X_vocab.update({\"'\" : 0, '-' : 0})\n",
    "sz2 = 0\n",
    "for gr in dictionary.keys():\n",
    "    for l in gr:\n",
    "        if l in X_vocab.keys():\n",
    "            X_vocab[l] += 1\n",
    "        else:\n",
    "            X_vocab.update({'UNK': 0})\n",
    "            print(gr)\n",
    "    if len(gr) > sz2:\n",
    "        sz2 = len(gr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('G', 16816), ('D', 21402), ('W', 6829), ('A', 54333), ('Q', 832), ('T', 35700), ('E', 69983), ('F', 8552), ('Z', 3918), ('J', 1662), (\"'\", 4907), ('-', 649), ('K', 11002), ('Y', 9888), ('L', 35662), ('H', 17889), ('S', 46389), ('M', 19204), ('X', 1424), ('C', 23850), ('V', 6467), ('O', 39591), ('I', 46686), ('N', 44939), ('P', 14006), ('R', 47637), ('B', 13850), ('U', 18607)])\n"
     ]
    }
   ],
   "source": [
    "print(X_vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "X_sorted = [k for k, v in sorted(X_vocab.items(), key=operator.itemgetter(1))][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "X_let_to_ix = {'ZERO' : 0}\n",
    "v = 1\n",
    "for k in X_sorted:\n",
    "    X_let_to_ix.update({k : v})\n",
    "    v += 1\n",
    "X_let_to_ix.update({\"BGN\" : v})\n",
    "grapheme_sz = v + 1\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ix_to_let = dict([(v, k) for k, v in X_let_to_ix.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "phoneme2int = {}\n",
    "v = 1\n",
    "for phoneme in phoneme_set:\n",
    "    phoneme2int.update({phoneme : v})\n",
    "    v += 1\n",
    "print(v)\n",
    "phoneme2int.update({\"BGN\" : v})\n",
    "phoneme_sz = v + 1\n",
    "int2phoneme = dict([(v, k) for (k, v) in phoneme2int.items()])\n",
    "print(phoneme_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L_AH_M_Y_UW' 'M_AY_N_D_IH_NG' 'S_T_R_AY_P_T' 'K_EH_N'\n",
      " 'K_AA_N_F_ER_AH_N_S' 'K_AA_N_F_R_AH_N_S' 'IH_M_AH_L_EY_T'\n",
      " 'T_R_AE_N_Z_G_R_EH_S' 'R_AE_B_AH_L' 'EH_R_SH_EH_R']\n"
     ]
    }
   ],
   "source": [
    "print(Y_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sz1 = X_data.shape[0]\n",
    "sz2 = max(map(len, X_data)) + 1\n",
    "sz3 = sz2\n",
    "X_train = np.zeros((sz1, sz2), dtype=np.int)\n",
    "Y_train = np.zeros((sz1, sz3), dtype=np.int)\n",
    "i, j = 0, 0\n",
    "for g in X_data:\n",
    "    X_train[i][0] = grapheme_sz - 1\n",
    "    Y_train[i][0] = phoneme_sz - 1\n",
    "    j = 1\n",
    "    for l in g:\n",
    "        X_train[i][j] = X_let_to_ix[l]\n",
    "        j += 1\n",
    "    j = 1\n",
    "    for ph in dictionary[g].split('_'):\n",
    "        Y_train[i][j] = phoneme2int[ph]\n",
    "        j += 1\n",
    "    X_train[i] = X_train[i][::-1]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89056, 35)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 26 13  1  4 12  1  9 29]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 15  6  4 11  6  4 12 29]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 11  1 16  4  3  8  5 29]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  6  1 18 29]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1 10  6  1  3  1 20  6  7 10 29]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40 39 17 34 22 32  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]\n",
      " [40 34  2  9  1  3 31  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]\n",
      " [40 33 25 16  2 15 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]\n",
      " [40 29 18  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]\n",
      " [40 29 36  9 26 16 17  9 33  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BGN', 'C', 'O', 'N', 'F', 'E', 'R', 'E', 'N', 'C', 'E']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: X_ix_to_let[x], [29, 10, 7, 6, 20, 1, 3, 1, 6, 10, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BGN', 'Y', 'S', 'L', 'W', 'P', 'AY', 'L', 'F']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: int2phoneme[x], [40, 22, 33, 39, 14, 15, 2, 39, 26])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89056, 35, 30)\n",
      "(89056, 35, 41)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((sz1, sz2, grapheme_sz))\n",
    "y = np.zeros((sz1, sz3, phoneme_sz))\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "max_len, feats = X.shape[1], X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5528a22d8f45e4b592cbb014932e51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(sz1)):\n",
    "    for j in range(sz2):\n",
    "        X[i, j, X_train[i, j]] = 1\n",
    "    for k in range(sz3):\n",
    "        y[i, k, Y_train[i, k]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89056, 35, 30) (89056, 35, 41)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "outs = y.shape[2]\n",
    "hidden_l = 64\n",
    "batch_size = 100\n",
    "epochs = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(max_len, feats)))\n",
    "model.add(LSTM(hidden_l, return_sequences=True))\n",
    "model.add(LSTM(hidden_l, return_sequences=True))\n",
    "model.add(LSTM(hidden_l, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(outs, activation='softmax')))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "12600/89056 [===>..........................] - ETA: 6:46 - loss: nan"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, y, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((1, sz2, grapheme_sz), dtype=np.int)\n",
    "for j in range(sz2):\n",
    "    x[0, j, X_train[4, j]] = 1\n",
    "\n",
    "pred = model.predict(x, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 35, 41)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    return int2phoneme[np.argmax(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"
     ]
    }
   ],
   "source": [
    "pred = pred[0]\n",
    "int2phoneme.update({0 : ' '})\n",
    "print('_'.join(map(sample, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

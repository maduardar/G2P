{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('train.txt', 'r')\n",
    "word_dict = {}\n",
    "X_data, Y_data = [], []\n",
    "for lines in text:\n",
    "    line = lines.split()\n",
    "    for words in line[1:]:\n",
    "        word_dict.update({line[0] : words})\n",
    "        X_data.append(line[0])\n",
    "        Y_data.append(words)\n",
    "X_data, Y_data = np.array(X_data), np.array(Y_data)\n",
    "dictionary = word_dict\n",
    "reverse_dictionary = dict([(v, k) for k, v in dictionary.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LEMIEUX' 'MINDING' 'STRIPED' 'KEN' 'CONFERENCE' 'CONFERENCE' 'IMMOLATE'\n",
      " 'TRANSGRESS' 'RABBLE' 'AIRSHARE']\n"
     ]
    }
   ],
   "source": [
    "print(X_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L_AH_M_Y_UW' 'M_AY_N_D_IH_NG' 'S_T_R_AY_P_T' 'K_EH_N'\n",
      " 'K_AA_N_F_ER_AH_N_S' 'K_AA_N_F_R_AH_N_S' 'IH_M_AH_L_EY_T'\n",
      " 'T_R_AE_N_Z_G_R_EH_S' 'R_AE_B_AH_L' 'EH_R_SH_EH_R']\n"
     ]
    }
   ],
   "source": [
    "print(Y_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Баловство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U \t 0 \t AH\n",
      "Y \t 566 \t K\n",
      "P \t 9570 \t S\n",
      "L \t 19266 \t AO\n",
      "G \t 6147 \t S\n",
      "T \t 17969 \t AH\n",
      "J \t 0 \t Y\n",
      "A \t 0 \t AE\n",
      "D \t 11817 \t D\n",
      "K \t 5407 \t K\n",
      "I \t 0 \t L\n",
      "Z \t 2054 \t AA\n",
      "H \t 0 \t HH\n",
      "O \t 0 \t OW\n",
      "V \t 4893 \t V\n",
      "Q \t 0 \t R\n",
      "E \t 0 \t AH\n",
      "C \t 0 \t IH\n",
      "M \t 12595 \t M\n",
      "S \t 16711 \t S\n",
      "X \t 0 \t K\n",
      "B \t 9748 \t B\n",
      "F \t 5572 \t SH\n",
      "W \t 2871 \t W\n",
      "R \t 20430 \t R\n",
      "N \t 21143 \t N\n"
     ]
    }
   ],
   "source": [
    "simb2phonDict = {}\n",
    "gr2coinc = {}\n",
    "from string import ascii_uppercase\n",
    "for let in ascii_uppercase:\n",
    "    gr2coinc.update({let: 0})\n",
    "phoneme_set = set()\n",
    "phonemes = reverse_dictionary.keys()\n",
    "ok = 0\n",
    "sz3 = 0\n",
    "for phoneme in phonemes:\n",
    "    grapheme = list(reverse_dictionary[phoneme])\n",
    "    phoneme = phoneme.split('_')\n",
    "    if len(phoneme) > sz3:\n",
    "        sz3 = len(phoneme)\n",
    "    for p in phoneme:\n",
    "        phoneme_set.add(p)\n",
    "    sz = min(len(grapheme), len(phoneme))\n",
    "    for i in range(sz):\n",
    "        simb2phonDict.update({grapheme[i]: phoneme[i]})\n",
    "        if grapheme[i] == phoneme[i]:\n",
    "            gr2coinc[grapheme[i]] += 1\n",
    "for g in gr2coinc.keys():\n",
    "    print(g, \"\\t\", gr2coinc[g], \"\\t\", simb2phonDict[g])\n",
    "# for g in simb2phonDict.keys():\n",
    "#     print(g, \"\\t\", simb2phonDict[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_vocab = {}\n",
    "for let in ascii_uppercase:\n",
    "    X_vocab.update({let: 0})\n",
    "X_vocab.update({\"'\" : 0, '-' : 0})\n",
    "sz2 = 0\n",
    "for gr in dictionary.keys():\n",
    "    for l in gr:\n",
    "        if l in X_vocab.keys():\n",
    "            X_vocab[l] += 1\n",
    "        else:\n",
    "            X_vocab.update({'UNK': 0})\n",
    "            print(gr)\n",
    "    if len(gr) > sz2:\n",
    "        sz2 = len(gr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('U', 18607), ('Y', 9888), ('P', 14006), ('L', 35662), ('G', 16816), ('T', 35700), ('J', 1662), ('A', 54333), ('D', 21402), ('K', 11002), ('I', 46686), (\"'\", 4907), ('Z', 3918), ('H', 17889), ('O', 39591), ('-', 649), ('V', 6467), ('Q', 832), ('E', 69983), ('C', 23850), ('M', 19204), ('S', 46389), ('X', 1424), ('B', 13850), ('F', 8552), ('W', 6829), ('R', 47637), ('N', 44939)])\n"
     ]
    }
   ],
   "source": [
    "print(X_vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "X_sorted = [k for k, v in sorted(X_vocab.items(), key=operator.itemgetter(1))][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "X_let_to_ix = {'ZERO' : 0}\n",
    "v = 1\n",
    "for k in X_sorted:\n",
    "    X_let_to_ix.update({k : v})\n",
    "    v += 1\n",
    "X_let_to_ix.update({\"BGN\" : v})\n",
    "grapheme_sz = v + 1\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ix_to_let = dict([(v, k) for k, v in X_let_to_ix.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "phoneme2int = {}\n",
    "v = 1\n",
    "for phoneme in phoneme_set:\n",
    "    phoneme2int.update({phoneme : v})\n",
    "    v += 1\n",
    "print(v)\n",
    "phoneme2int.update({\"BGN\" : v})\n",
    "phoneme_sz = v + 1\n",
    "int2phoneme = dict([(v, k) for (k, v) in phoneme2int.items()])\n",
    "print(phoneme_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L_AH_M_Y_UW' 'M_AY_N_D_IH_NG' 'S_T_R_AY_P_T' 'K_EH_N'\n",
      " 'K_AA_N_F_ER_AH_N_S' 'K_AA_N_F_R_AH_N_S' 'IH_M_AH_L_EY_T'\n",
      " 'T_R_AE_N_Z_G_R_EH_S' 'R_AE_B_AH_L' 'EH_R_SH_EH_R']\n"
     ]
    }
   ],
   "source": [
    "print(Y_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz1 = X_data.shape[0]\n",
    "sz2 = max(map(len, X_data)) + 1\n",
    "sz3 = sz2\n",
    "X_train = np.zeros((sz1, sz2), dtype=np.int)\n",
    "Y_train = np.zeros((sz1, sz3), dtype=np.int)\n",
    "i, j = 0, 0\n",
    "for g in X_data:\n",
    "    X_train[i][0] = grapheme_sz - 1\n",
    "    Y_train[i][0] = phoneme_sz - 1\n",
    "    j = 1\n",
    "    for l in g:\n",
    "        X_train[i][j] = X_let_to_ix[l]\n",
    "        j += 1\n",
    "    j = 1\n",
    "    for ph in dictionary[g].split('_'):\n",
    "        Y_train[i][j] = phoneme2int[ph]\n",
    "        j += 1\n",
    "    X_train[i] = X_train[i][::-1]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89056, 35)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 26 13  1  4 12  1  9 29]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 15  6  4 11  6  4 12 29]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 11  1 16  4  3  8  5 29]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  6  1 18 29]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1 10  6  1  3  1 20  6  7 10 29]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40 19  2 10 17 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]\n",
      " [40 10 35 39 21 32  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]\n",
      " [40 26  4 15 35 18  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]\n",
      " [40 22 16 39  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]\n",
      " [40 22 33 39 14 15  2 39 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BGN', 'C', 'O', 'N', 'F', 'E', 'R', 'E', 'N', 'C', 'E']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: X_ix_to_let[x], [29, 10, 7, 6, 20, 1, 3, 1, 6, 10, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BGN', 'K', 'AA', 'N', 'F', 'R', 'AH', 'N', 'S']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: int2phoneme[x], [40, 22, 33, 39, 14, 15, 2, 39, 26])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89056, 35, 30)\n",
      "(89056, 35, 41)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((sz1, sz2, grapheme_sz))\n",
    "y = np.zeros((sz1, sz3, phoneme_sz))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2e57fac7d648caa9d8c99f9892308f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(sz1)):\n",
    "    for j in range(sz2):\n",
    "        X[i, j, X_train[i, j]] = 1\n",
    "    for k in range(sz3):\n",
    "        y[i, k, Y_train[i, k]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89056, 35, 30) (89056, 35, 41)\n",
      "Compiling the model ...\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "max_len = X.shape[1]\n",
    "n_feats = X.shape[2]\n",
    "n_outs = y.shape[2]\n",
    "n_hidden = 32\n",
    " \n",
    "print(\"Compiling the model ...\")\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0., input_shape=(max_len, n_feats)),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    LSTM(n_hidden, return_sequences=True),\n",
    "    TimeDistributed(Dense(n_outs, activation='softmax')),\n",
    "])\n",
    "optimizer = RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "89056/89056 [==============================] - 8430s 95ms/step - loss: 0.6959\n",
      "Epoch 2/5\n",
      " 9840/89056 [==>...........................] - ETA: 2:07:22 - loss: 0.6816"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-319-d913ee231952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1221\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                         raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, y, batch_size=5, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow's version : 1.0 (or more)\n"
     ]
    }
   ],
   "source": [
    "# Backward compatibility for TensorFlow's version 0.12: \n",
    "try:\n",
    "    tf.nn.seq2seq = tf.contrib.legacy_seq2seq\n",
    "    tf.nn.rnn_cell = tf.contrib.rnn\n",
    "    tf.nn.rnn_cell.GRUCell = tf.contrib.rnn.GRUCell\n",
    "    print(\"TensorFlow's version : 1.0 (or more)\")\n",
    "except: \n",
    "    print(\"TensorFlow's version : 0.12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.4'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((1, sz2, grapheme_sz), dtype=np.int)\n",
    "for j in range(sz2):\n",
    "    x[0, j, X_train[1, j]] = 1\n",
    "\n",
    "pred = model.predict(x, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 35, 41)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=0.5):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return int2phoneme[np.argmax(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGN_K_IH_N_AH_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"
     ]
    }
   ],
   "source": [
    "pred = pred[0]\n",
    "int2phoneme.update({0 : ' '})\n",
    "print('_'.join(map(sample, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Hyperparametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_x, sample_y = generate_x_y_data(isTrain=True, batch_size=3)\n",
    "print(\"Dimensions of the dataset for 3 X and 3 Y training examples : \")\n",
    "print(sample_x.shape)\n",
    "print(sample_y.shape)\n",
    "print(\"(seq_length, batch_size, output_dim)\")\n",
    "\n",
    "# Internal neural network parameters\n",
    "seq_length = sample_x.shape[0]  # Time series will have the same past and future (to be predicted) lenght. \n",
    "batch_size = 5  # Low value used for live demo purposes - 100 and 1000 would be possible too, crank that up!\n",
    "\n",
    "output_dim = input_dim = sample_x.shape[-1]  # Output dimension (e.g.: multiple signals at once, tied in time)\n",
    "hidden_dim = 12  # Count of hidden neurons in the recurrent units. \n",
    "layers_stacked_count = 2  # Number of stacked recurrent cells, on the neural depth axis. \n",
    "\n",
    "# Optmizer: \n",
    "learning_rate = 0.007  # Small lr helps not to diverge during training. \n",
    "nb_iters = 150  # How many times we perform a training step (therefore how many times we show a batch). \n",
    "lr_decay = 0.92  # default: 0.9 . Simulated annealing.\n",
    "momentum = 0.5  # default: 0.0 . Momentum technique in weights update\n",
    "lambda_l2_reg = 0.003  # L2 regularization of weights - avoids overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = grapheme_sz\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 32\n",
    "decoder_hidden_units = encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs_embedded,\n",
    "    dtype=tf.float32, time_major=True,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 32) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 32) dtype=float32>)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs_embedded,\n",
    "\n",
    "    initial_state=encoder_final_state,\n",
    "\n",
    "    dtype=tf.float32, time_major=True, scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, ?, 30) dtype=float32>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_encoded:\n",
      "[[6 3 9]\n",
      " [0 4 8]\n",
      " [0 0 7]]\n",
      "decoder inputs:\n",
      "[[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "decoder predictions:\n",
      "[[ 4  4 19]\n",
      " [ 4  4 23]\n",
      " [23 23 23]\n",
      " [ 2 23 23]]\n"
     ]
    }
   ],
   "source": [
    "batch_ = [[6], [3, 4], [9, 8, 7]]\n",
    "\n",
    "batch_, batch_length_ = helpers.batch(batch_)\n",
    "print('batch_encoded:\\n' + str(batch_))\n",
    "\n",
    "din_, dlen_ = helpers.batch(np.ones(shape=(3, 1), dtype=np.int32),\n",
    "                            max_sequence_length=4)\n",
    "print('decoder inputs:\\n' + str(din_))\n",
    "\n",
    "pred_ = sess.run(decoder_prediction,\n",
    "    feed_dict={\n",
    "        encoder_inputs: batch_,\n",
    "        decoder_inputs: din_,\n",
    "    })\n",
    "print('decoder predictions:\\n' + str(pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[8, 9, 7, 9, 4, 7, 4, 6]\n",
      "[3, 3, 6, 4]\n",
      "[7, 6, 8, 2, 5, 4, 5]\n",
      "[5, 4, 8, 4, 7, 4, 4]\n",
      "[9, 2, 6, 5]\n",
      "[8, 6, 9, 6, 4, 9, 6, 4]\n",
      "[8, 2, 5, 3, 8, 7]\n",
      "[8, 4, 9, 7]\n",
      "[3, 2, 7, 2, 2, 5]\n",
      "[4, 4, 2, 7, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, _ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, _ = helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 3.367331027984619\n",
      "  sample 1:\n",
      "    input     > [5 3 7 9 0 0 0 0]\n",
      "    predicted > [ 4  4 13 24  5  5  5  2  2]\n",
      "  sample 2:\n",
      "    input     > [9 5 6 3 9 0 0 0]\n",
      "    predicted > [ 4  4  4  6 13  5  5 14 14]\n",
      "  sample 3:\n",
      "    input     > [8 6 2 4 0 0 0 0]\n",
      "    predicted > [ 4  5  5  5  6  6  6  2 29]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.3213512599468231\n",
      "  sample 1:\n",
      "    input     > [9 7 6 3 9 4 0 0]\n",
      "    predicted > [9 7 6 3 9 4 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 4 6 0 0 0 0 0]\n",
      "    predicted > [2 4 6 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 5 9 3 8 3 7 0]\n",
      "    predicted > [2 5 3 3 3 3 7 1 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.1668933629989624\n",
      "  sample 1:\n",
      "    input     > [6 7 2 9 6 0 0 0]\n",
      "    predicted > [6 7 2 9 6 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 3 8 6 5 0 0 0]\n",
      "    predicted > [3 3 8 6 5 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 7 6 3 4 0 0 0]\n",
      "    predicted > [8 7 6 3 4 1 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.09818622469902039\n",
      "  sample 1:\n",
      "    input     > [3 7 5 6 6 7 0 0]\n",
      "    predicted > [3 7 5 6 6 7 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 4 2 2 2 6 5 6]\n",
      "    predicted > [4 2 2 2 2 6 7 6 1]\n",
      "  sample 3:\n",
      "    input     > [7 6 2 0 0 0 0 0]\n",
      "    predicted > [7 6 2 1 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0897 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3EVEEpDCXUQkAf0fFBSEJg2MF8MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134aa1ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
